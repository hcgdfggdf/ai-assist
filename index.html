<script type="module">
  import { pipeline, env } from "https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.2.1";

  // --- CRITICAL FIXES ---
  // Disable local models so it doesn't look for files on your server
  env.allowLocalModels = false; 
  // Allow remote models to fetch from Hugging Face
  env.allowRemoteModels = true;
  
  // Use a specific proxy or clear it to avoid CORS issues
  env.backends.onnx.wasm.proxy = false; 
  
  // Some browsers fail if numThreads is too high or set incorrectly
  env.backends.onnx.wasm.numThreads = 1;

  const messagesDiv = document.getElementById("messages");
  const inputField = document.getElementById("user-input");
  const sendBtn = document.getElementById("send-btn");
  const statusDot = document.getElementById("status-dot");
  const statusText = document.getElementById("status-text");

  let generator = null;
  let chatHistory = [{ role: "system", content: "You are Sharon, a sarcastic AI assistant." }];

  async function init() {
    try {
      statusText.innerText = "Requesting brain cells from the cloud...";
      
      // Load the model
      // We use 'onnx-community/SmolLM2-135M-Instruct' which is highly compatible
      generator = await pipeline("text-generation", "onnx-community/SmolLM2-135M-Instruct", {
        device: "wasm", // Force WASM for maximum compatibility across browsers
        progress_callback: (p) => {
          if (p.status === 'progress') {
            statusText.innerText = `Downloading: ${Math.round(p.progress)}%`;
          }
        }
      });

      statusDot.classList.add("ready");
      statusText.innerText = "I'm in! Let's cause some chaos.";
      inputField.disabled = false;
      sendBtn.disabled = false;
      inputField.placeholder = "Say something...";
    } catch (e) {
      console.error("Initialization Error:", e);
      statusText.innerText = "Access Denied: " + e.message;
    }
  }

  function addMsg(text, type) {
    const d = document.createElement("div");
    d.className = `message ${type}-msg`;
    d.innerText = text;
    messagesDiv.appendChild(d);
    messagesDiv.scrollTop = messagesDiv.scrollHeight;
  }

  async function talk() {
    const val = inputField.value.trim();
    if (!val || !generator) return;

    addMsg(val, "user");
    chatHistory.push({ role: "user", content: val });
    inputField.value = "";
    inputField.disabled = true;
    sendBtn.disabled = true;

    const t = document.createElement("div");
    t.className = "message ai-msg";
    t.innerText = "Sharon is thinking...";
    messagesDiv.appendChild(t);

    try {
      const output = await generator(chatHistory, { 
        max_new_tokens: 60, 
        temperature: parseFloat(document.getElementById("temp-input").value) || 0.7,
        do_sample: true,
        return_full_text: false
      });

      if (messagesDiv.contains(t)) messagesDiv.removeChild(t);
      
      // Handle different output formats between Transformers.js versions
      const response = output[0].generated_text.at(-1).content;
      
      addMsg(response, "ai");
      chatHistory.push({ role: "assistant", content: response });
      
      // Keep memory short to prevent slowdowns
      if (chatHistory.length > 8) {
          chatHistory = [chatHistory[0], ...chatHistory.slice(-6)];
      }
    } catch (err) {
      if (messagesDiv.contains(t)) messagesDiv.removeChild(t);
      addMsg("Error: " + err.message, "ai");
    }
    
    inputField.disabled = false;
    inputField.focus();
    sendBtn.disabled = false;
  }

  sendBtn.onclick = talk;
  inputField.onkeypress = (e) => { if(e.key === 'Enter') talk(); };
  init();
</script>
